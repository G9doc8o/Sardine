title: 【转载】屏蔽爬虫请求的四种方式
date: '2021-06-18 23:06:12'
toc: true
permalink: /articles/2021/06/18/1624028772585.html
category: 
 - 转载
 - 爬虫
tags: 
 - 转载
 - 屏蔽
 - 爬虫
 - 请求
 - 方式
---

本文转载自：[屏蔽爬虫请求的四种方式 | 白宦成](https://www.ixiqin.com/2021/02/shielding-the-crawler-request-four-ways/)

---

在进行应用开发的过程中，难免会遇见爬虫爬取数据的。正常情况下，爬虫的数据爬取不应影响业务系统的正常运行。但毕竟都是人写的代码，难免会出现 Bug ，在 Bug 的情况下，爬虫可能会对业务系统发起超出日常水平的请求，从而使业务系统开始出现故障。在这种情况下，就需要对爬虫进行屏蔽。


<!-- more -->


屏蔽爬虫，由内而外，可以分为四个不同的方式来屏蔽。

1. 屏蔽 UA
2. 在主机层面屏蔽 IP
3. 在安全组层面屏蔽 IP
4. 在 CDN 层面屏蔽 IP

## 1. 屏蔽 UA

爬虫一般而言，都会有特殊的 User Agent ，比如 *Baiduspider* 就是百度的爬虫；*Googlebot* 就是 Google 的爬虫。

在第一阶段，你可以针对 User Agent 进行屏蔽，这部分只需要在 HTTP Server 层面加入相应的屏蔽代码即可。

以最常用的反向代理服务器 Nginx 为例，你可以在站点的配置文件中添加如下代码来屏蔽百度和 Google 的爬虫访问。

```
if ($http_user_agent ~* "Baiduspider|Googlebot")  
{
    return 403;
}
```

上述这段代码可以实现在 Nginx 检测到访问者的 User Agent 包含特定的字符的时候，返回 403 报错，拒绝访问服务。

## 2. 在主机层面屏蔽 IP

除了针对 User Agent ，有些时候是特定的来源的 IP 疯狂的访问，那也可以考虑针对 IP 进行封禁。

考虑到这部分，最常见的是使用主机自带的防火墙机制，来屏蔽来自特定来源的 IP。以 Linux 为例，可以通过 iptables 来完成相应的功能。

在 Linux 下，输入如下命令，来添加 iptables 屏蔽

```bash
iptables -I INPUT -s 8.0.0.1 -j DROP
```

上述命令，就可以在 iptables 中添加针对 8.0.0.1 的请求，所有来自 8.0.0.1 的请求都会被抛弃。

## 3. 在安全组层面屏蔽 IP

在如今的业务模式下，大家大多使用的是云服务器。如果你使用的是云服务器，则可以在用户的请求到达主机之前，直接在云服务商的内部网关层面直接丢弃。

你只需要在现有的安全组规则中新增一条屏蔽特定来源 IP 的规则，就可以实现在安全组层面上屏蔽特定的 IP。

![](https://b3logfile.com/file/2021/06/solo-fetchupload-5808181516179342577-abc0e9c9.png)## 4. 在 CDN 层面屏蔽 IP

现在我们的业务大多会使用 CDN 来完成数据的分发。在这种情况下，服务器获取到请求不是来自我们要屏蔽的 IP，因此，我们可以直接在 CDN 层面屏蔽掉爬虫的 IP。

现在的云服务商的 CDN 大多提供了 IP 白名单/黑名单的功能，你只需要将需要屏蔽的 IP 放在黑名单中，就可以实现在 CDN 层面屏蔽 IP。

![](https://b3logfile.com/file/2021/06/solo-fetchupload-4878768009416937409-402f8bde.png)## 总结

屏蔽爬虫的方式有多种多样，不过最为常见的主要就是这四种。当你找到了爬虫的特征，便可以很轻松的屏蔽它。

